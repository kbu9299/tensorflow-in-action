{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beyond Hello World, A Computer Vision Example\n",
    "\n",
    "![Fashion MNIST](./img/fashion-mnist.png)\n",
    "\n",
    "Reference: https://www.tensorflow.org/tutorials/keras/classification\n",
    "\n",
    "The images are 28x28 NumPy arrays, with pixel values ranging from 0 to 255. The *labels* are an array of integers, ranging from 0 to 9. These correspond to the *class* of clothing the image represents:\n",
    "\n",
    "![Fashion MNIST](./img/fashion-mnist-classes.png)\n",
    "\n",
    "Each image is mapped to a single label. Since the *class names* are not included with the dataset, store them here to use later when plotting the images:\n",
    "```\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_images = (60000, 28, 28)\n",
      "training_labels = (60000,)\n",
      "test_images = (10000, 28, 28)\n",
      "test_labels = (10000,)\n"
     ]
    }
   ],
   "source": [
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(\"training_images = {}\".format(training_images.shape))\n",
    "print(\"training_labels = {}\".format(training_labels.shape))\n",
    "print(\"test_images = {}\".format(test_images.shape))\n",
    "print(\"test_labels = {}\".format(test_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(training_images[0], cmap='gray_r'); # inverted gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0\n",
      "    0   1   4   0   0   0   0   1   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62\n",
      "   54   0   0   0   1   3   4   0   0   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134\n",
      "  144 123  23   0   0   0   0  12  10   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178\n",
      "  107 156 161 109  64  23  77 130  72  15]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216\n",
      "  216 163 127 121 122 146 141  88 172  66]\n",
      " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229\n",
      "  223 223 215 213 164 127 123 196 229   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228\n",
      "  235 227 224 222 224 221 223 245 173   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198\n",
      "  180 212 210 211 213 223 220 243 202   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192\n",
      "  169 227 208 218 224 212 226 197 209  52]\n",
      " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203\n",
      "  198 221 215 213 222 220 245 119 167  56]\n",
      " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240\n",
      "  232 213 218 223 234 217 217 209  92   0]\n",
      " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219\n",
      "  222 221 216 223 229 215 218 255  77   0]\n",
      " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208\n",
      "  211 218 224 223 219 215 224 244 159   0]\n",
      " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230\n",
      "  224 234 176 188 250 248 233 238 215   0]\n",
      " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223\n",
      "  255 255 221 234 221 211 220 232 246   0]\n",
      " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221\n",
      "  188 154 191 210 204 209 222 228 225   0]\n",
      " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117\n",
      "  168 219 221 215 217 223 223 224 229  29]\n",
      " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245\n",
      "  239 223 218 212 209 222 220 221 230  67]\n",
      " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216\n",
      "  199 206 186 181 177 172 181 205 206 115]\n",
      " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191\n",
      "  195 191 198 192 176 156 167 177 210  92]\n",
      " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209\n",
      "  210 210 211 188 188 194 192 216 170   0]\n",
      " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179\n",
      "  182 182 181 176 166 168  99  58   0   0]\n",
      " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(training_labels[0])\n",
    "print(training_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing (or scaling)\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00392157 0.         0.         0.05098039 0.28627451 0.\n",
      "  0.         0.00392157 0.01568627 0.         0.         0.\n",
      "  0.         0.00392157 0.00392157 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01176471 0.         0.14117647 0.53333333 0.49803922 0.24313725\n",
      "  0.21176471 0.         0.         0.         0.00392157 0.01176471\n",
      "  0.01568627 0.         0.         0.01176471]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02352941 0.         0.4        0.8        0.69019608 0.5254902\n",
      "  0.56470588 0.48235294 0.09019608 0.         0.         0.\n",
      "  0.         0.04705882 0.03921569 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.60784314 0.9254902  0.81176471 0.69803922\n",
      "  0.41960784 0.61176471 0.63137255 0.42745098 0.25098039 0.09019608\n",
      "  0.30196078 0.50980392 0.28235294 0.05882353]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.00392157\n",
      "  0.         0.27058824 0.81176471 0.8745098  0.85490196 0.84705882\n",
      "  0.84705882 0.63921569 0.49803922 0.4745098  0.47843137 0.57254902\n",
      "  0.55294118 0.34509804 0.6745098  0.25882353]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00392157 0.00392157 0.00392157\n",
      "  0.         0.78431373 0.90980392 0.90980392 0.91372549 0.89803922\n",
      "  0.8745098  0.8745098  0.84313725 0.83529412 0.64313725 0.49803922\n",
      "  0.48235294 0.76862745 0.89803922 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.71764706 0.88235294 0.84705882 0.8745098  0.89411765\n",
      "  0.92156863 0.89019608 0.87843137 0.87058824 0.87843137 0.86666667\n",
      "  0.8745098  0.96078431 0.67843137 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.75686275 0.89411765 0.85490196 0.83529412 0.77647059\n",
      "  0.70588235 0.83137255 0.82352941 0.82745098 0.83529412 0.8745098\n",
      "  0.8627451  0.95294118 0.79215686 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00392157 0.01176471 0.\n",
      "  0.04705882 0.85882353 0.8627451  0.83137255 0.85490196 0.75294118\n",
      "  0.6627451  0.89019608 0.81568627 0.85490196 0.87843137 0.83137255\n",
      "  0.88627451 0.77254902 0.81960784 0.20392157]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.02352941 0.\n",
      "  0.38823529 0.95686275 0.87058824 0.8627451  0.85490196 0.79607843\n",
      "  0.77647059 0.86666667 0.84313725 0.83529412 0.87058824 0.8627451\n",
      "  0.96078431 0.46666667 0.65490196 0.21960784]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.01568627 0.         0.\n",
      "  0.21568627 0.9254902  0.89411765 0.90196078 0.89411765 0.94117647\n",
      "  0.90980392 0.83529412 0.85490196 0.8745098  0.91764706 0.85098039\n",
      "  0.85098039 0.81960784 0.36078431 0.        ]\n",
      " [0.         0.         0.00392157 0.01568627 0.02352941 0.02745098\n",
      "  0.00784314 0.         0.         0.         0.         0.\n",
      "  0.92941176 0.88627451 0.85098039 0.8745098  0.87058824 0.85882353\n",
      "  0.87058824 0.86666667 0.84705882 0.8745098  0.89803922 0.84313725\n",
      "  0.85490196 1.         0.30196078 0.        ]\n",
      " [0.         0.01176471 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.24313725 0.56862745 0.8\n",
      "  0.89411765 0.81176471 0.83529412 0.86666667 0.85490196 0.81568627\n",
      "  0.82745098 0.85490196 0.87843137 0.8745098  0.85882353 0.84313725\n",
      "  0.87843137 0.95686275 0.62352941 0.        ]\n",
      " [0.         0.         0.         0.         0.07058824 0.17254902\n",
      "  0.32156863 0.41960784 0.74117647 0.89411765 0.8627451  0.87058824\n",
      "  0.85098039 0.88627451 0.78431373 0.80392157 0.82745098 0.90196078\n",
      "  0.87843137 0.91764706 0.69019608 0.7372549  0.98039216 0.97254902\n",
      "  0.91372549 0.93333333 0.84313725 0.        ]\n",
      " [0.         0.22352941 0.73333333 0.81568627 0.87843137 0.86666667\n",
      "  0.87843137 0.81568627 0.8        0.83921569 0.81568627 0.81960784\n",
      "  0.78431373 0.62352941 0.96078431 0.75686275 0.80784314 0.8745098\n",
      "  1.         1.         0.86666667 0.91764706 0.86666667 0.82745098\n",
      "  0.8627451  0.90980392 0.96470588 0.        ]\n",
      " [0.01176471 0.79215686 0.89411765 0.87843137 0.86666667 0.82745098\n",
      "  0.82745098 0.83921569 0.80392157 0.80392157 0.80392157 0.8627451\n",
      "  0.94117647 0.31372549 0.58823529 1.         0.89803922 0.86666667\n",
      "  0.7372549  0.60392157 0.74901961 0.82352941 0.8        0.81960784\n",
      "  0.87058824 0.89411765 0.88235294 0.        ]\n",
      " [0.38431373 0.91372549 0.77647059 0.82352941 0.87058824 0.89803922\n",
      "  0.89803922 0.91764706 0.97647059 0.8627451  0.76078431 0.84313725\n",
      "  0.85098039 0.94509804 0.25490196 0.28627451 0.41568627 0.45882353\n",
      "  0.65882353 0.85882353 0.86666667 0.84313725 0.85098039 0.8745098\n",
      "  0.8745098  0.87843137 0.89803922 0.11372549]\n",
      " [0.29411765 0.8        0.83137255 0.8        0.75686275 0.80392157\n",
      "  0.82745098 0.88235294 0.84705882 0.7254902  0.77254902 0.80784314\n",
      "  0.77647059 0.83529412 0.94117647 0.76470588 0.89019608 0.96078431\n",
      "  0.9372549  0.8745098  0.85490196 0.83137255 0.81960784 0.87058824\n",
      "  0.8627451  0.86666667 0.90196078 0.2627451 ]\n",
      " [0.18823529 0.79607843 0.71764706 0.76078431 0.83529412 0.77254902\n",
      "  0.7254902  0.74509804 0.76078431 0.75294118 0.79215686 0.83921569\n",
      "  0.85882353 0.86666667 0.8627451  0.9254902  0.88235294 0.84705882\n",
      "  0.78039216 0.80784314 0.72941176 0.70980392 0.69411765 0.6745098\n",
      "  0.70980392 0.80392157 0.80784314 0.45098039]\n",
      " [0.         0.47843137 0.85882353 0.75686275 0.70196078 0.67058824\n",
      "  0.71764706 0.76862745 0.8        0.82352941 0.83529412 0.81176471\n",
      "  0.82745098 0.82352941 0.78431373 0.76862745 0.76078431 0.74901961\n",
      "  0.76470588 0.74901961 0.77647059 0.75294118 0.69019608 0.61176471\n",
      "  0.65490196 0.69411765 0.82352941 0.36078431]\n",
      " [0.         0.         0.29019608 0.74117647 0.83137255 0.74901961\n",
      "  0.68627451 0.6745098  0.68627451 0.70980392 0.7254902  0.7372549\n",
      "  0.74117647 0.7372549  0.75686275 0.77647059 0.8        0.81960784\n",
      "  0.82352941 0.82352941 0.82745098 0.7372549  0.7372549  0.76078431\n",
      "  0.75294118 0.84705882 0.66666667 0.        ]\n",
      " [0.00784314 0.         0.         0.         0.25882353 0.78431373\n",
      "  0.87058824 0.92941176 0.9372549  0.94901961 0.96470588 0.95294118\n",
      "  0.95686275 0.86666667 0.8627451  0.75686275 0.74901961 0.70196078\n",
      "  0.71372549 0.71372549 0.70980392 0.69019608 0.65098039 0.65882353\n",
      "  0.38823529 0.22745098 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.15686275 0.23921569 0.17254902 0.28235294 0.16078431\n",
      "  0.1372549  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(training_labels[0])\n",
    "print(training_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), # input_shape=(28, 28) \n",
    "                                   tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                                   tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.4991 - accuracy: 0.8250\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.3751 - accuracy: 0.8646\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.3374 - accuracy: 0.8766\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.3127 - accuracy: 0.8854\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.2938 - accuracy: 0.8916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd6fe146b50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = tf.optimizers.Adam(), # or simply optimizer='adam'\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 0s - loss: 0.2490 - accuracy: 0.8811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33393328174352643, 0.8811]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.6439833e-05 1.1717050e-07 3.6635362e-07 1.4042611e-07 4.0740423e-07\n",
      "  3.1953403e-03 6.8336285e-06 6.4588010e-02 1.8019079e-04 9.3200213e-01]]\n",
      "tf.Tensor(9, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "classification_prob = model.predict(tf.expand_dims(test_images[0], axis=0))\n",
    "print(classification_prob)\n",
    "print(tf.math.argmax(classification_prob[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: `model` accepts only the form of (None, 28, 28) so we need to expand one dimension along with axis `0`:\n",
    "* test_images[0].shape: (28, 28)\n",
    "* tf.expand_dims(test_images[0], axis=0).shape): (1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.64398550e-05 1.17170266e-07 3.66354300e-07 1.40425954e-07\n",
      "  4.07403832e-07 3.19534284e-03 6.83362805e-06 6.45880997e-02\n",
      "  1.80191128e-04 9.32002008e-01]\n",
      " [2.17861507e-05 1.17527946e-10 9.90410924e-01 6.15839113e-09\n",
      "  7.48664746e-03 1.72514089e-13 2.08058441e-03 2.27153247e-14\n",
      "  1.30825750e-08 6.90817096e-16]]\n",
      "tf.Tensor([9 2], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "classification_prob = model.predict(tf.stack([test_images[0], test_images[1]]))\n",
    "print(classification_prob)\n",
    "print(tf.math.argmax(classification_prob, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding `Input` and `Output` shape is Important!**\n",
    "\n",
    "![Input and Ouput Shape](img/stack_argmax.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Callback function\n",
    "* `loss` will be logged by default  \n",
    "* need to add `metrics=['accuracy']` in order to access `accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('accuracy') > 0.88:\n",
    "            print(\"\\nReached 88% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 - 5s - loss: 0.4715 - accuracy: 0.8331\n",
      "Epoch 2/5\n",
      "60000/60000 - 6s - loss: 0.3567 - accuracy: 0.8704\n",
      "Epoch 3/5\n",
      "60000/60000 - 7s - loss: 0.3242 - accuracy: 0.8800\n",
      "Epoch 4/5\n",
      "\n",
      "Reached 88% accuracy so cancelling training!\n",
      "60000/60000 - 7s - loss: 0.3006 - accuracy: 0.8881\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.47153526089986164, 0.35666005692481995, 0.32420468151569365, 0.3006202197253704], 'accuracy': [0.83306664, 0.87035, 0.8799667, 0.88815]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
