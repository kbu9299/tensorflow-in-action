{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Computer Vision Accuracy using Convolutions\n",
    "* Deep Neural Network without Convolutions\n",
    "* Convolutional Neural Network\n",
    "* Dataset: Fashion MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='sgd', \n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 - 5s - loss: 0.7450 - accuracy: 0.7580\n",
      "Epoch 2/5\n",
      "60000/60000 - 4s - loss: 0.5178 - accuracy: 0.8238\n",
      "Epoch 3/5\n",
      "60000/60000 - 4s - loss: 0.4720 - accuracy: 0.8379\n",
      "Epoch 4/5\n",
      "60000/60000 - 2s - loss: 0.4466 - accuracy: 0.8450\n",
      "Epoch 5/5\n",
      "60000/60000 - 3s - loss: 0.4287 - accuracy: 0.8520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fabbc32a710>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_images, training_labels, epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 0s - loss: 0.3788 - accuracy: 0.8376\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate(test_images, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network\n",
    "\n",
    "By stacking Convolution and Pooling layers in front of Dense layers, the higher accuracy can be achievable.   \n",
    "\n",
    "![Simple CNN architecuture](img/simple-cnn-model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded training_images shape:  (60000, 28, 28, 1)\n",
      "Expanded test_images shape:  (60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = tf.expand_dims(training_images, axis=3)\n",
    "test_images = tf.expand_dims(test_images, axis=3)\n",
    "print(\"Expanded training_images shape: \", training_images.shape)\n",
    "print(\"Expanded test_images shape: \", training_images.shape)\n",
    "\n",
    "# normalization\n",
    "training_images = tf.dtypes.cast(training_images, tf.float32) / 255\n",
    "test_images = tf.dtypes.cast(test_images, tf.float32) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 243,786\n",
      "Trainable params: 243,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)), \n",
    "    tf.keras.layers.MaxPooling2D(2, 2), \n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 - 6s - loss: 0.4386 - accuracy: 0.8404\n",
      "Epoch 2/5\n",
      "60000/60000 - 5s - loss: 0.2929 - accuracy: 0.8916\n",
      "Epoch 3/5\n",
      "60000/60000 - 5s - loss: 0.2450 - accuracy: 0.9092\n",
      "Epoch 4/5\n",
      "60000/60000 - 4s - loss: 0.2108 - accuracy: 0.9223\n",
      "Epoch 5/5\n",
      "60000/60000 - 4s - loss: 0.1846 - accuracy: 0.9321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fabbc05a290>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_images, training_labels, epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 0s - loss: 0.2580 - accuracy: 0.9105\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate(test_images, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Convolutions and Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: conv2d/Identity:0\n",
      "1: max_pooling2d/Identity:0\n",
      "2: conv2d_1/Identity:0\n",
      "3: max_pooling2d_1/Identity:0\n",
      "4: flatten_1/Identity:0\n",
      "5: dense_2/Identity:0\n",
      "6: dense_3/Identity:0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "f, axarr = plt.subplots(3, 4)\n",
    "\n",
    "FIRST_IMAGE=0\n",
    "SECOND_IMAGE=7\n",
    "THIRD_IMAGE=26\n",
    "CONVOLUTION_NUMBER = 28\n",
    "\n",
    "from tensorflow.keras import models\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "\n",
    "for i, layer_output in enumerate(layer_outputs):\n",
    "    print(\"{}: {}\".format(i, layer_output.name))\n",
    "\n",
    "activation_model = tf.keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "\n",
    "for x in range(4):\n",
    "    f1 = activation_model.predict(tf.reshape(test_images[FIRST_IMAGE], (1, 28, 28, 1)))[x]\n",
    "    axarr[0, x].axis('off')\n",
    "    axarr[0, x].imshow(f1[0, :, :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "    f2 = activation_model.predict(tf.reshape(test_images[SECOND_IMAGE], (1, 28, 28, 1)))[x]\n",
    "    axarr[1, x].axis('off')\n",
    "    axarr[1, x].imshow(f2[0, :, :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "    f3 = activation_model.predict(tf.reshape(test_images[THIRD_IMAGE], (1, 28, 28, 1)))[x]\n",
    "    axarr[2, x].axis('off')\n",
    "    axarr[2, x].imshow(f3[0, :, :, CONVOLUTION_NUMBER], cmap='inferno')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Tuning\n",
    "In this example, we adopt a simple archtecture but increase the training iterations and we can achive the higher accuracy (~ 98.6% for test images) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 - 4s - loss: 0.1442 - accuracy: 0.9571\n",
      "Epoch 2/10\n",
      "60000/60000 - 4s - loss: 0.0488 - accuracy: 0.9847\n",
      "Epoch 3/10\n",
      "60000/60000 - 4s - loss: 0.0318 - accuracy: 0.9900\n",
      "Epoch 4/10\n",
      "60000/60000 - 3s - loss: 0.0197 - accuracy: 0.9935\n",
      "Epoch 5/10\n",
      "60000/60000 - 4s - loss: 0.0142 - accuracy: 0.9955\n",
      "Epoch 6/10\n",
      "60000/60000 - 4s - loss: 0.0103 - accuracy: 0.9967\n",
      "Epoch 7/10\n",
      "60000/60000 - 4s - loss: 0.0069 - accuracy: 0.9978\n",
      "Epoch 8/10\n",
      "60000/60000 - 5s - loss: 0.0066 - accuracy: 0.9979\n",
      "Epoch 9/10\n",
      "60000/60000 - 6s - loss: 0.0050 - accuracy: 0.9985\n",
      "Epoch 10/10\n",
      "60000/60000 - 5s - loss: 0.0042 - accuracy: 0.9985\n",
      "10000/1 - 0s - loss: 0.0267 - accuracy: 0.9870\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "training_images=training_images/255.0\n",
    "test_images=test_images.reshape(10000, 28, 28, 1)\n",
    "test_images=test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=10, verbose=2)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
